{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "388f37e9",
   "metadata": {},
   "source": [
    "# üéÆ Super Mario Advance 2 - NEAT Evolution\n",
    "\n",
    "This notebook trains an AI agent to play Super Mario Advance 2 using **NEAT (NeuroEvolution of Augmenting Topologies)**.\n",
    "\n",
    "## Why NEAT instead of PPO?\n",
    "1. **No keyboard hijacking** - Direct emulator API access via `mgba` library\n",
    "2. **Efficient for games** - Evolves network topology, great for platformers\n",
    "3. **No gradient computation** - Works well with sparse rewards\n",
    "4. **Famous success** - This is the algorithm behind MarI/O!\n",
    "\n",
    "## Components:\n",
    "1. **mgba-py**: Direct GBA emulator control (no screen capture needed)\n",
    "2. **NEAT-Python**: Neuroevolution algorithm\n",
    "3. **Parallel evaluation**: Train multiple genomes simultaneously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d38abe1",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "\n",
    "Install `neat-python` for the NEAT algorithm. We'll use mGBA's scripting interface via subprocess for emulator control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca244595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neat-python in ./.venv/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.10/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.10.8)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.10/site-packages (12.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install neat-python numpy opencv-python matplotlib pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be76e6",
   "metadata": {},
   "source": [
    "## 2. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a36bc4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROM exists: True\n",
      "NEAT config exists: True\n",
      "ROM path: /Users/informatics/Documents/GitHub/reinforced-super-mario/data/Super Mario Advance 2.gba\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import neat\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "ROM_PATH = os.path.abspath(\"data/Super Mario Advance 2.gba\")\n",
    "CONFIG_PATH = os.path.abspath(\"neat-config.txt\")\n",
    "CHECKPOINT_DIR = \"./models\"\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"ROM exists: {os.path.exists(ROM_PATH)}\")\n",
    "print(f\"NEAT config exists: {os.path.exists(CONFIG_PATH)}\")\n",
    "print(f\"ROM path: {ROM_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fec356",
   "metadata": {},
   "source": [
    "## 3. GBA Emulator Wrapper\n",
    "\n",
    "This class wraps mGBA using subprocess for **headless emulation** - runs in the background without stealing your keyboard or mouse!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77904598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GBAEmulator class defined!\n",
      "\n",
      "Key benefits:\n",
      "  ‚Ä¢ Runs in background (no window stealing)\n",
      "  ‚Ä¢ No keyboard/mouse hijacking\n",
      "  ‚Ä¢ Currently in simulation mode for algorithm testing\n",
      "\n",
      "Note: Using simulation mode while we test the NEAT algorithm.\n",
      "      Real mGBA integration can be added once the algorithm works.\n"
     ]
    }
   ],
   "source": [
    "class GBAEmulator:\n",
    "    \"\"\"\n",
    "    GBA Emulator wrapper using mGBA in headless mode.\n",
    "    \n",
    "    This runs in the background - no window stealing or keyboard hijacking!\n",
    "    Currently in simulation mode for algorithm testing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # GBA Screen dimensions\n",
    "    SCREEN_WIDTH = 240\n",
    "    SCREEN_HEIGHT = 160\n",
    "    \n",
    "    # Downscaled observation for neural network (13x13 = 169 inputs)\n",
    "    OBS_SIZE = 13\n",
    "    \n",
    "    # GBA Button mappings (bit positions)\n",
    "    BUTTONS = {\n",
    "        'A': 0,\n",
    "        'B': 1,\n",
    "        'SELECT': 2,\n",
    "        'START': 3,\n",
    "        'RIGHT': 4,\n",
    "        'LEFT': 5,\n",
    "        'UP': 6,\n",
    "        'DOWN': 7,\n",
    "        'R': 8,\n",
    "        'L': 9\n",
    "    }\n",
    "    \n",
    "    def __init__(self, rom_path, mgba_path=\"/opt/homebrew/bin/mgba\"):\n",
    "        \"\"\"Initialize the emulator with a ROM.\"\"\"\n",
    "        self.rom_path = rom_path\n",
    "        self.mgba_path = mgba_path\n",
    "        self.process = None\n",
    "        self.frame_buffer = None\n",
    "        self.running = False\n",
    "        \n",
    "        # Game state (simulated for now since direct memory access requires Lua script)\n",
    "        self.mario_x = 0\n",
    "        self.mario_y = 0\n",
    "        self.coins = 0\n",
    "        self.lives = 5\n",
    "        self.step_count = 0\n",
    "        \n",
    "    def start(self):\n",
    "        \"\"\"Start mGBA in headless mode.\"\"\"\n",
    "        # For now, we'll simulate the emulator since Lua socket support varies\n",
    "        # This allows the NEAT algorithm to work while we figure out the best \n",
    "        # mGBA integration approach\n",
    "        self.running = True\n",
    "        self.step_count = 0\n",
    "        self.mario_x = 50  # Starting position\n",
    "        self.mario_y = 100\n",
    "        self.coins = 0\n",
    "        self.lives = 5\n",
    "        \n",
    "        # Generate a simple initial frame (grayscale noise for now)\n",
    "        self.frame_buffer = np.random.randint(0, 50, (self.SCREEN_HEIGHT, self.SCREEN_WIDTH, 3), dtype=np.uint8)\n",
    "        \n",
    "        print(\"‚úÖ Emulator started (simulation mode)\")\n",
    "        print(\"   Note: Using simulated environment for algorithm testing\")\n",
    "        return True\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the emulator to initial state.\"\"\"\n",
    "        self.step_count = 0\n",
    "        self.mario_x = 50\n",
    "        self.mario_y = 100\n",
    "        self.coins = 0\n",
    "        self.lives = 5\n",
    "        self.frame_buffer = np.random.randint(0, 50, (self.SCREEN_HEIGHT, self.SCREEN_WIDTH, 3), dtype=np.uint8)\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def get_frame(self):\n",
    "        \"\"\"Get the current frame as a numpy array (RGB).\"\"\"\n",
    "        if self.frame_buffer is None:\n",
    "            return np.zeros((self.SCREEN_HEIGHT, self.SCREEN_WIDTH, 3), dtype=np.uint8)\n",
    "        return self.frame_buffer.copy()\n",
    "    \n",
    "    def get_observation(self):\n",
    "        \"\"\"Get downscaled grayscale observation for the neural network.\"\"\"\n",
    "        frame = self.get_frame()\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        # Downscale to OBS_SIZE x OBS_SIZE\n",
    "        small = cv2.resize(gray, (self.OBS_SIZE, self.OBS_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        # Normalize to 0-1 range\n",
    "        normalized = small.astype(np.float32) / 255.0\n",
    "        return normalized.flatten()\n",
    "    \n",
    "    def get_mario_x(self):\n",
    "        \"\"\"Get Mario's X position.\"\"\"\n",
    "        return self.mario_x\n",
    "    \n",
    "    def get_mario_y(self):\n",
    "        \"\"\"Get Mario's Y position.\"\"\"\n",
    "        return self.mario_y\n",
    "    \n",
    "    def get_coins(self):\n",
    "        \"\"\"Get coin count.\"\"\"\n",
    "        return self.coins\n",
    "    \n",
    "    def get_lives(self):\n",
    "        \"\"\"Get lives remaining.\"\"\"\n",
    "        return self.lives\n",
    "    \n",
    "    def press_buttons(self, buttons):\n",
    "        \"\"\"\n",
    "        Press the specified buttons (simulated).\n",
    "        \n",
    "        Args:\n",
    "            buttons: List of button names to press (e.g., ['A', 'RIGHT'])\n",
    "        \"\"\"\n",
    "        # Simulate button effects on game state\n",
    "        for button in buttons:\n",
    "            if button == 'RIGHT':\n",
    "                self.mario_x += np.random.randint(1, 5)\n",
    "            elif button == 'LEFT':\n",
    "                self.mario_x -= np.random.randint(1, 3)\n",
    "            elif button == 'A':  # Jump\n",
    "                self.mario_y -= np.random.randint(0, 10)\n",
    "            elif button == 'B':  # Run\n",
    "                if 'RIGHT' in buttons:\n",
    "                    self.mario_x += np.random.randint(2, 6)\n",
    "        \n",
    "        # Random coin collection\n",
    "        if np.random.random() < 0.02:  # 2% chance per step\n",
    "            self.coins += 1\n",
    "        \n",
    "        # Random death (very low probability)\n",
    "        if np.random.random() < 0.001:\n",
    "            self.lives -= 1\n",
    "    \n",
    "    def step(self, buttons, frames=4):\n",
    "        \"\"\"\n",
    "        Execute an action for a number of frames.\n",
    "        \n",
    "        Args:\n",
    "            buttons: List of button names to press\n",
    "            frames: Number of frames to hold the buttons\n",
    "            \n",
    "        Returns:\n",
    "            observation, info dict\n",
    "        \"\"\"\n",
    "        for _ in range(frames):\n",
    "            self.press_buttons(buttons)\n",
    "            self.step_count += 1\n",
    "        \n",
    "        # Update frame buffer (simulate screen changes)\n",
    "        self._update_frame_buffer()\n",
    "        \n",
    "        obs = self.get_observation()\n",
    "        info = {\n",
    "            'x': self.mario_x,\n",
    "            'y': self.mario_y,\n",
    "            'coins': self.coins,\n",
    "            'lives': self.lives\n",
    "        }\n",
    "        return obs, info\n",
    "    \n",
    "    def _update_frame_buffer(self):\n",
    "        \"\"\"Update the frame buffer to simulate game visuals.\"\"\"\n",
    "        # Create a simple gradient based on mario's position\n",
    "        base = np.zeros((self.SCREEN_HEIGHT, self.SCREEN_WIDTH, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Sky (blue gradient)\n",
    "        for y in range(self.SCREEN_HEIGHT // 2):\n",
    "            base[y, :, 2] = 150 + y  # Blue channel\n",
    "        \n",
    "        # Ground (green/brown)\n",
    "        base[self.SCREEN_HEIGHT // 2:, :, 1] = 100  # Green channel\n",
    "        \n",
    "        # Simple \"Mario\" representation\n",
    "        mario_screen_x = min(max(self.mario_x % self.SCREEN_WIDTH, 10), self.SCREEN_WIDTH - 20)\n",
    "        mario_screen_y = min(max(self.mario_y, 50), self.SCREEN_HEIGHT - 30)\n",
    "        \n",
    "        # Draw Mario as a red rectangle\n",
    "        y_start = max(0, mario_screen_y - 10)\n",
    "        y_end = min(self.SCREEN_HEIGHT, mario_screen_y + 10)\n",
    "        x_start = max(0, mario_screen_x - 5)\n",
    "        x_end = min(self.SCREEN_WIDTH, mario_screen_x + 5)\n",
    "        \n",
    "        base[y_start:y_end, x_start:x_end, 0] = 255  # Red\n",
    "        \n",
    "        self.frame_buffer = base\n",
    "    \n",
    "    def run_frames(self, n=1):\n",
    "        \"\"\"Run n frames without any input.\"\"\"\n",
    "        for _ in range(n):\n",
    "            self.step_count += 1\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close the emulator.\"\"\"\n",
    "        self.running = False\n",
    "        if self.process:\n",
    "            self.process.terminate()\n",
    "            self.process = None\n",
    "\n",
    "print(\"‚úÖ GBAEmulator class defined!\")\n",
    "print()\n",
    "print(\"Key benefits:\")\n",
    "print(\"  ‚Ä¢ Runs in background (no window stealing)\")\n",
    "print(\"  ‚Ä¢ No keyboard/mouse hijacking\")\n",
    "print(\"  ‚Ä¢ Currently in simulation mode for algorithm testing\")\n",
    "print()\n",
    "print(\"Note: Using simulation mode while we test the NEAT algorithm.\")\n",
    "print(\"      Real mGBA integration can be added once the algorithm works.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba399856",
   "metadata": {},
   "source": [
    "## 4. Test the Emulator\n",
    "\n",
    "Quick test to make sure the emulator works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6197af18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GBA emulator...\n",
      "(This runs in simulation mode - no window will appear!)\n",
      "\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator loaded successfully!\n",
      "Observation shape: (169,) (flattened 13x13)\n",
      "\n",
      "Taking test steps...\n",
      "  Step 1: Action=['RIGHT'], Mario X=61, Y=100\n",
      "  Step 2: Action=['RIGHT', 'A'], Mario X=71, Y=84\n",
      "  Step 3: Action=['RIGHT', 'B'], Mario X=94, Y=84\n",
      "  Step 4: Action=['A'], Mario X=94, Y=68\n",
      "  Step 5: Action=NONE, Mario X=94, Y=68\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Emulator test passed!\n"
     ]
    }
   ],
   "source": [
    "# Test the emulator\n",
    "print(\"Testing GBA emulator...\")\n",
    "print(\"(This runs in simulation mode - no window will appear!)\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    emu = GBAEmulator(ROM_PATH)\n",
    "    emu.start()\n",
    "    obs = emu.reset()\n",
    "    \n",
    "    print(f\"‚úÖ Emulator loaded successfully!\")\n",
    "    print(f\"Observation shape: {obs.shape} (flattened {GBAEmulator.OBS_SIZE}x{GBAEmulator.OBS_SIZE})\")\n",
    "    print()\n",
    "    \n",
    "    # Take a few test steps\n",
    "    print(\"Taking test steps...\")\n",
    "    actions = [['RIGHT'], ['RIGHT', 'A'], ['RIGHT', 'B'], ['A'], []]\n",
    "    for i, action in enumerate(actions):\n",
    "        obs, info = emu.step(action)\n",
    "        print(f\"  Step {i+1}: Action={action or 'NONE'}, Mario X={info['x']}, Y={info['y']}\")\n",
    "    \n",
    "    # Show current frame\n",
    "    frame = emu.get_frame()\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.imshow(frame)\n",
    "    plt.title(\"Super Mario Advance 2 - Simulated Frame\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    emu.close()\n",
    "    print()\n",
    "    print(\"‚úÖ Emulator test passed!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"‚ùå Emulator test failed: {e}\")\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da0148",
   "metadata": {},
   "source": [
    "## 5. NEAT Genome Evaluator\n",
    "\n",
    "This is the core of the training loop. Each genome (neural network) plays the game and gets a fitness score based on how far Mario travels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa8b4fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NEAT evaluator defined!\n",
      "\n",
      "Fitness function:\n",
      "  ‚Ä¢ Primary: Rightward progress (max X position)\n",
      "  ‚Ä¢ Bonus: +10 per coin collected\n",
      "  ‚Ä¢ Termination: Death or stuck for 200+ frames\n"
     ]
    }
   ],
   "source": [
    "# Action mappings for NEAT outputs (6 outputs)\n",
    "# Each output neuron corresponds to: A, B, LEFT, RIGHT, UP, DOWN\n",
    "# We threshold at 0.5 to determine if button is pressed\n",
    "\n",
    "NEAT_ACTIONS = ['A', 'B', 'LEFT', 'RIGHT', 'UP', 'DOWN']\n",
    "\n",
    "def outputs_to_buttons(outputs):\n",
    "    \"\"\"Convert NEAT network outputs to button presses.\"\"\"\n",
    "    buttons = []\n",
    "    for i, output in enumerate(outputs):\n",
    "        if output > 0.5:\n",
    "            buttons.append(NEAT_ACTIONS[i])\n",
    "    return buttons\n",
    "\n",
    "\n",
    "def evaluate_genome(genome, config, max_steps=1000, render=False):\n",
    "    \"\"\"\n",
    "    Evaluate a single genome by playing the game.\n",
    "    \n",
    "    Args:\n",
    "        genome: NEAT genome to evaluate\n",
    "        config: NEAT config\n",
    "        max_steps: Maximum steps per evaluation\n",
    "        render: Whether to render frames (for visualization)\n",
    "        \n",
    "    Returns:\n",
    "        fitness: The fitness score for this genome\n",
    "    \"\"\"\n",
    "    # Create the neural network from the genome\n",
    "    net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    \n",
    "    # Create emulator instance\n",
    "    emu = GBAEmulator(ROM_PATH)\n",
    "    emu.start()\n",
    "    obs = emu.reset()\n",
    "    \n",
    "    # Track fitness metrics\n",
    "    max_x = 0\n",
    "    total_coins = 0\n",
    "    start_lives = emu.get_lives()\n",
    "    frames_stuck = 0\n",
    "    \n",
    "    frames = [] if render else None\n",
    "    \n",
    "    for _ in range(max_steps):\n",
    "        # Get network output\n",
    "        outputs = net.activate(obs)\n",
    "        \n",
    "        # Convert to button presses\n",
    "        buttons = outputs_to_buttons(outputs)\n",
    "        \n",
    "        # Execute action\n",
    "        obs, info = emu.step(buttons, frames=4)\n",
    "        \n",
    "        # Update fitness metrics\n",
    "        current_x = info['x']\n",
    "        current_coins = info['coins']\n",
    "        current_lives = info['lives']\n",
    "        \n",
    "        # Track max X position (rightward progress)\n",
    "        if current_x > max_x:\n",
    "            max_x = current_x\n",
    "            frames_stuck = 0\n",
    "        else:\n",
    "            frames_stuck += 1\n",
    "        \n",
    "        # Track coins collected\n",
    "        if current_coins > total_coins:\n",
    "            total_coins = current_coins\n",
    "        \n",
    "        # Collect frames for rendering\n",
    "        if render:\n",
    "            frames.append(emu.get_frame())\n",
    "        \n",
    "        # Check termination conditions\n",
    "        # Died (lost a life)\n",
    "        if current_lives < start_lives:\n",
    "            break\n",
    "        \n",
    "        # Stuck for too long (not making progress)\n",
    "        if frames_stuck > 200:\n",
    "            break\n",
    "    \n",
    "    emu.close()\n",
    "    \n",
    "    # Calculate fitness\n",
    "    # Primary: rightward progress (X position)\n",
    "    # Secondary: coins collected\n",
    "    fitness = max_x + (total_coins * 10)\n",
    "    \n",
    "    if render:\n",
    "        return fitness, frames\n",
    "    return fitness\n",
    "\n",
    "\n",
    "print(\"‚úÖ NEAT evaluator defined!\")\n",
    "print()\n",
    "print(\"Fitness function:\")\n",
    "print(\"  ‚Ä¢ Primary: Rightward progress (max X position)\")\n",
    "print(\"  ‚Ä¢ Bonus: +10 per coin collected\")\n",
    "print(\"  ‚Ä¢ Termination: Death or stuck for 200+ frames\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac70715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NEAT reporter defined with auto-save!\n",
      "\n",
      "New feature:\n",
      "  ‚Ä¢ üíæ Best genome auto-saved whenever fitness improves\n",
      "  ‚Ä¢ Saved to: ./models/best_genome.pkl\n"
     ]
    }
   ],
   "source": [
    "def eval_genomes(genomes, config):\n",
    "    \"\"\"\n",
    "    Evaluate all genomes in the population.\n",
    "    This is called by NEAT each generation.\n",
    "    \"\"\"\n",
    "    for genome_id, genome in genomes:\n",
    "        try:\n",
    "            genome.fitness = evaluate_genome(genome, config)\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating genome {genome_id}: {e}\")\n",
    "            genome.fitness = 0\n",
    "\n",
    "\n",
    "class NEATReporter(neat.reporting.BaseReporter):\n",
    "    \"\"\"Custom reporter to track training progress and auto-save best genome.\"\"\"\n",
    "    \n",
    "    def __init__(self, save_path=CHECKPOINT_DIR):\n",
    "        self.generation = 0\n",
    "        self.best_fitness = 0\n",
    "        self.best_genome = None\n",
    "        self.fitness_history = []\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def start_generation(self, generation):\n",
    "        self.generation = generation\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Generation {generation}\")\n",
    "        print('='*50)\n",
    "    \n",
    "    def end_generation(self, config, population, species_set):\n",
    "        # Find best genome this generation (handle None fitness values)\n",
    "        best = None\n",
    "        for sid, s in species_set.species.items():\n",
    "            for m in s.members.values():\n",
    "                # Skip genomes with None fitness\n",
    "                if m.fitness is None:\n",
    "                    continue\n",
    "                # Compare fitness values safely\n",
    "                if best is None or best.fitness is None or m.fitness > best.fitness:\n",
    "                    best = m\n",
    "        \n",
    "        if best and best.fitness is not None:\n",
    "            self.fitness_history.append(best.fitness)\n",
    "            \n",
    "            print(f\"Best fitness this gen: {best.fitness:.0f}\")\n",
    "            print(f\"Best fitness overall: {self.best_fitness:.0f}\")\n",
    "            print(f\"Species: {len(species_set.species)}\")\n",
    "            \n",
    "            # Auto-save if this is a new best!\n",
    "            if best.fitness > self.best_fitness:\n",
    "                self.best_fitness = best.fitness\n",
    "                self.best_genome = best\n",
    "                \n",
    "                # Save best genome immediately\n",
    "                best_path = f'{self.save_path}/best_genome.pkl'\n",
    "                with open(best_path, 'wb') as f:\n",
    "                    pickle.dump(best, f)\n",
    "                print(f\"  üíæ New best saved! (fitness: {best.fitness:.0f})\")\n",
    "    \n",
    "    def post_evaluate(self, config, population, species, best_genome):\n",
    "        pass\n",
    "    \n",
    "    def found_solution(self, config, generation, best):\n",
    "        print(f\"\\nüèÜ Solution found in generation {generation}!\")\n",
    "        print(f\"Best fitness: {best.fitness:.0f}\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ NEAT reporter defined with auto-save!\")\n",
    "print()\n",
    "print(\"New feature:\")\n",
    "print(\"  ‚Ä¢ üíæ Best genome auto-saved whenever fitness improves\")\n",
    "print(\"  ‚Ä¢ Saved to: ./models/best_genome.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d467db9",
   "metadata": {},
   "source": [
    "## 6. Train with NEAT\n",
    "\n",
    "Run the NEAT evolution! This will evolve neural network topologies to play Mario.\n",
    "\n",
    "**Note:** You can safely use your computer while this runs - no keyboard/mouse hijacking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ff66a2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ NEAT configuration loaded!\n",
      "\n",
      "Population size: 50\n",
      "Network inputs: 169 (13x13 downscaled screen)\n",
      "Network outputs: 6 (A, B, LEFT, RIGHT, UP, DOWN)\n"
     ]
    }
   ],
   "source": [
    "# Load NEAT configuration\n",
    "config = neat.Config(\n",
    "    neat.DefaultGenome,\n",
    "    neat.DefaultReproduction,\n",
    "    neat.DefaultSpeciesSet,\n",
    "    neat.DefaultStagnation,\n",
    "    CONFIG_PATH\n",
    ")\n",
    "\n",
    "print(\"‚úÖ NEAT configuration loaded!\")\n",
    "print()\n",
    "print(f\"Population size: {config.pop_size}\")\n",
    "print(f\"Network inputs: {config.genome_config.num_inputs} (13x13 downscaled screen)\")\n",
    "print(f\"Network outputs: {config.genome_config.num_outputs} (A, B, LEFT, RIGHT, UP, DOWN)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a575a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Population created!\n",
      "\n",
      "Ready to train. Run the next cell to start evolution.\n"
     ]
    }
   ],
   "source": [
    "# Create the NEAT population\n",
    "population = neat.Population(config)\n",
    "\n",
    "# Add reporters for output\n",
    "population.add_reporter(neat.StdOutReporter(True))\n",
    "stats = neat.StatisticsReporter()\n",
    "population.add_reporter(stats)\n",
    "reporter = NEATReporter()\n",
    "population.add_reporter(reporter)\n",
    "\n",
    "# Add checkpointing (saves every 5 generations)\n",
    "checkpointer = neat.Checkpointer(\n",
    "    generation_interval=5,\n",
    "    filename_prefix=f'{CHECKPOINT_DIR}/neat-checkpoint-'\n",
    ")\n",
    "population.add_reporter(checkpointer)\n",
    "\n",
    "print(\"‚úÖ Population created!\")\n",
    "print()\n",
    "print(\"Ready to train. Run the next cell to start evolution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5379772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß¨ Starting NEAT Evolution!\n",
      "Running for 50 generations...\n",
      "\n",
      "‚úÖ You can use your computer normally while this runs!\n",
      "   (No keyboard/mouse hijacking)\n",
      "\n",
      "\n",
      " ****** Running generation 0 ****** \n",
      "\n",
      "\n",
      "==================================================\n",
      "Generation 0\n",
      "==================================================\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "‚úÖ Emulator started (simulation mode)\n",
      "   Note: Using simulated environment for algorithm testing\n",
      "Population's average fitness: 1597.78000 stdev: 3051.22760\n",
      "Best fitness: 13309.00000 - size: (6, 1014) - species 1 - id 34\n",
      "Average adjusted fitness: 0.117\n",
      "Mean genetic distance 1.112, standard deviation 0.140\n",
      "Population of 50 members in 1 species (after reproduction):\n",
      "   ID   age  size   fitness   adj fit  stag\n",
      "  ====  ===  ====  =========  =======  ====\n",
      "     1    0    50  13309.000    0.117     0\n",
      "Total extinctions: 0\n",
      "Generation time: 4.236 sec\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Run evolution\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m winner \u001b[38;5;241m=\u001b[39m \u001b[43mpopulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_genomes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_GENERATIONS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/GitHub/reinforced-super-mario/.venv/lib/python3.10/site-packages/neat/population.py:147\u001b[0m, in \u001b[0;36mPopulation.run\u001b[0;34m(self, fitness_function, n)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# Divide the new population into species.\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecies\u001b[38;5;241m.\u001b[39mspeciate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration)\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreporters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspecies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeneration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mno_fitness_termination:\n",
      "File \u001b[0;32m~/Documents/GitHub/reinforced-super-mario/.venv/lib/python3.10/site-packages/neat/reporting.py:32\u001b[0m, in \u001b[0;36mReporterSet.end_generation\u001b[0;34m(self, config, population, species_set)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mend_generation\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, population, species_set):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreporters:\n\u001b[0;32m---> 32\u001b[0m         \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpopulation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspecies_set\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 35\u001b[0m, in \u001b[0;36mNEATReporter.end_generation\u001b[0;34m(self, config, population, species_set)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sid, s \u001b[38;5;129;01min\u001b[39;00m species_set\u001b[38;5;241m.\u001b[39mspecies\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m s\u001b[38;5;241m.\u001b[39mmembers\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m---> 35\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitness\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitness\u001b[49m:\n\u001b[1;32m     36\u001b[0m             best \u001b[38;5;241m=\u001b[39m m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best:\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# üéÆ RUN NEAT EVOLUTION\n",
    "# Adjust num_generations based on your patience!\n",
    "# Good results typically need 50-200+ generations\n",
    "\n",
    "NUM_GENERATIONS = 50  # Start small, increase for better results\n",
    "\n",
    "print(\"üß¨ Starting NEAT Evolution!\")\n",
    "print(f\"Running for {NUM_GENERATIONS} generations...\")\n",
    "print()\n",
    "print(\"‚úÖ You can use your computer normally while this runs!\")\n",
    "print(\"   (No keyboard/mouse hijacking)\")\n",
    "print()\n",
    "\n",
    "# Run evolution\n",
    "winner = population.run(eval_genomes, NUM_GENERATIONS)\n",
    "\n",
    "print()\n",
    "print(\"=\"*50)\n",
    "print(\"üèÜ EVOLUTION COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Best genome fitness: {winner.fitness:.0f}\")\n",
    "print(f\"Best genome has {len(winner.connections)} connections\")\n",
    "print(f\"Best genome has {len([n for n in winner.nodes if n not in config.genome_config.input_keys and n not in config.genome_config.output_keys])} hidden nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea03a12",
   "metadata": {},
   "source": [
    "## 7. Save the Best Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6db5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model saved to ./models/super_mario_ppo_final.zip\n"
     ]
    }
   ],
   "source": [
    "# Save the best genome\n",
    "winner_path = f'{CHECKPOINT_DIR}/winner_genome.pkl'\n",
    "with open(winner_path, 'wb') as f:\n",
    "    pickle.dump(winner, f)\n",
    "print(f\"‚úÖ Best genome saved to: {winner_path}\")\n",
    "\n",
    "# Also save the stats\n",
    "stats_path = f'{CHECKPOINT_DIR}/training_stats.pkl'\n",
    "with open(stats_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'fitness_history': reporter.fitness_history,\n",
    "        'best_fitness': reporter.best_fitness\n",
    "    }, f)\n",
    "print(f\"‚úÖ Training stats saved to: {stats_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a115ba9e",
   "metadata": {},
   "source": [
    "## 8. Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77085ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot fitness over generations\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(reporter.fitness_history, 'b-', linewidth=2)\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Best Fitness')\n",
    "plt.title('Best Fitness Over Generations')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot fitness statistics from NEAT stats reporter\n",
    "if hasattr(stats, 'most_fit_genomes') and stats.most_fit_genomes:\n",
    "    generations = range(len(stats.most_fit_genomes))\n",
    "    best_fitness = [g.fitness for g in stats.most_fit_genomes]\n",
    "    avg_fitness = stats.get_fitness_mean()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(generations, best_fitness, 'b-', label='Best', linewidth=2)\n",
    "    plt.plot(generations, avg_fitness, 'g--', label='Mean', linewidth=1)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Fitness')\n",
    "    plt.title('Population Fitness Statistics')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Final Statistics:\")\n",
    "print(f\"  Best fitness achieved: {reporter.best_fitness:.0f}\")\n",
    "print(f\"  Generations run: {len(reporter.fitness_history)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b713411",
   "metadata": {},
   "source": [
    "## 9. Watch the Winner Play!\n",
    "\n",
    "Visualize the best evolved network playing the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d58684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from matplotlib import animation\n",
    "\n",
    "# Load winner if not in memory\n",
    "try:\n",
    "    winner\n",
    "except NameError:\n",
    "    winner_path = f'{CHECKPOINT_DIR}/winner_genome.pkl'\n",
    "    with open(winner_path, 'rb') as f:\n",
    "        winner = pickle.load(f)\n",
    "    print(f\"Loaded winner from {winner_path}\")\n",
    "\n",
    "def evaluate_genome_with_inputs(genome, config, max_steps=1000):\n",
    "    \"\"\"\n",
    "    Evaluate genome and record frames WITH input/output info for visualization.\n",
    "    Returns frames, observations, and button presses for MarI/O-style display.\n",
    "    \"\"\"\n",
    "    net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "    emu = GBAEmulator(ROM_PATH)\n",
    "    emu.start()\n",
    "    obs = emu.reset()\n",
    "    \n",
    "    # Recording data\n",
    "    frames = []\n",
    "    observations = []  # What the AI \"sees\" (13x13 grid)\n",
    "    button_history = []  # Which buttons are pressed each frame\n",
    "    output_history = []  # Raw network outputs\n",
    "    info_history = []  # Game state info\n",
    "    \n",
    "    max_x = 0\n",
    "    frames_stuck = 0\n",
    "    start_lives = emu.get_lives()\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        # Get network output\n",
    "        outputs = net.activate(obs)\n",
    "        buttons = outputs_to_buttons(outputs)\n",
    "        \n",
    "        # Record everything\n",
    "        frames.append(emu.get_frame())\n",
    "        observations.append(obs.reshape(GBAEmulator.OBS_SIZE, GBAEmulator.OBS_SIZE))\n",
    "        button_history.append(buttons)\n",
    "        output_history.append(outputs)\n",
    "        info_history.append({\n",
    "            'x': emu.get_mario_x(),\n",
    "            'y': emu.get_mario_y(),\n",
    "            'coins': emu.get_coins(),\n",
    "            'step': step\n",
    "        })\n",
    "        \n",
    "        # Execute action\n",
    "        obs, info = emu.step(buttons, frames=4)\n",
    "        \n",
    "        # Check termination\n",
    "        if info['x'] > max_x:\n",
    "            max_x = info['x']\n",
    "            frames_stuck = 0\n",
    "        else:\n",
    "            frames_stuck += 1\n",
    "        \n",
    "        if info['lives'] < start_lives or frames_stuck > 200:\n",
    "            break\n",
    "    \n",
    "    emu.close()\n",
    "    \n",
    "    fitness = max_x + (info['coins'] * 10)\n",
    "    \n",
    "    return {\n",
    "        'frames': frames,\n",
    "        'observations': observations,\n",
    "        'buttons': button_history,\n",
    "        'outputs': output_history,\n",
    "        'info': info_history,\n",
    "        'fitness': fitness\n",
    "    }\n",
    "\n",
    "# Record winner gameplay with full input/output data\n",
    "print(\"üé¨ Recording winner gameplay with MarI/O-style data...\")\n",
    "data = evaluate_genome_with_inputs(winner, config, max_steps=2000)\n",
    "print(f\"‚úÖ Recorded {len(data['frames'])} frames\")\n",
    "print(f\"Winner fitness: {data['fitness']:.0f}\")\n",
    "print()\n",
    "print(\"Run the next cell to see the MarI/O-style visualization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5944a47e",
   "metadata": {},
   "source": [
    "### MarI/O-Style Visualization\n",
    "\n",
    "This shows the AI playing like in the famous MarI/O video:\n",
    "- **Game Screen**: What's happening in the game\n",
    "- **AI Vision**: The 13√ó13 grid the neural network receives as input\n",
    "- **Network Outputs**: Bar chart showing each output neuron's activation (green = above 0.5 threshold = button pressed)\n",
    "- **Controller**: Visual representation of which buttons are being pressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c130b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mario_style_visualization(data, fps=15):\n",
    "    \"\"\"\n",
    "    Create a MarI/O-style visualization showing:\n",
    "    - Game screen (left)\n",
    "    - Neural network input grid - what the AI sees (middle)\n",
    "    - Controller with button presses (right)\n",
    "    \"\"\"\n",
    "    frames = data['frames']\n",
    "    observations = data['observations']\n",
    "    buttons = data['buttons']\n",
    "    outputs = data['outputs']\n",
    "    info = data['info']\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig = plt.figure(figsize=(16, 6))\n",
    "    gs = fig.add_gridspec(2, 4, width_ratios=[3, 1.5, 1.5, 1], height_ratios=[1, 1])\n",
    "    \n",
    "    # Game screen (large, left)\n",
    "    ax_game = fig.add_subplot(gs[:, 0])\n",
    "    ax_game.set_title(\"Game Screen\", fontsize=12, fontweight='bold')\n",
    "    ax_game.axis('off')\n",
    "    \n",
    "    # Neural network input (what AI sees)\n",
    "    ax_input = fig.add_subplot(gs[:, 1])\n",
    "    ax_input.set_title(\"AI Vision (13√ó13)\", fontsize=12, fontweight='bold')\n",
    "    ax_input.axis('off')\n",
    "    \n",
    "    # Network outputs (activation bars)\n",
    "    ax_outputs = fig.add_subplot(gs[:, 2])\n",
    "    ax_outputs.set_title(\"Network Outputs\", fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Controller visualization\n",
    "    ax_ctrl = fig.add_subplot(gs[:, 3])\n",
    "    ax_ctrl.set_title(\"Controller\", fontsize=12, fontweight='bold')\n",
    "    ax_ctrl.axis('off')\n",
    "    ax_ctrl.set_xlim(0, 100)\n",
    "    ax_ctrl.set_ylim(0, 100)\n",
    "    \n",
    "    # Initialize plots\n",
    "    img_game = ax_game.imshow(frames[0])\n",
    "    img_input = ax_input.imshow(observations[0], cmap='gray', vmin=0, vmax=1)\n",
    "    \n",
    "    # Output bar chart setup\n",
    "    button_names = ['A', 'B', 'LEFT', 'RIGHT', 'UP', 'DOWN']\n",
    "    y_pos = np.arange(len(button_names))\n",
    "    bars = ax_outputs.barh(y_pos, outputs[0], color='steelblue')\n",
    "    ax_outputs.set_yticks(y_pos)\n",
    "    ax_outputs.set_yticklabels(button_names)\n",
    "    ax_outputs.set_xlim(0, 1)\n",
    "    ax_outputs.axvline(x=0.5, color='red', linestyle='--', alpha=0.5, label='Threshold')\n",
    "    \n",
    "    # Controller button positions\n",
    "    ctrl_buttons = {\n",
    "        'UP': (30, 75, '‚Üë'),\n",
    "        'DOWN': (30, 45, '‚Üì'),\n",
    "        'LEFT': (15, 60, '‚Üê'),\n",
    "        'RIGHT': (45, 60, '‚Üí'),\n",
    "        'A': (80, 55, 'A'),\n",
    "        'B': (65, 45, 'B'),\n",
    "    }\n",
    "    \n",
    "    # Draw controller base\n",
    "    button_patches = {}\n",
    "    for btn, (x, y, label) in ctrl_buttons.items():\n",
    "        circle = plt.Circle((x, y), 8, facecolor='lightgray', edgecolor='black', linewidth=2)\n",
    "        ax_ctrl.add_patch(circle)\n",
    "        ax_ctrl.text(x, y, label, ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "        button_patches[btn] = circle\n",
    "    \n",
    "    # Info text\n",
    "    info_text = ax_game.text(5, 10, '', color='white', fontsize=10, \n",
    "                             bbox=dict(boxstyle='round', facecolor='black', alpha=0.7))\n",
    "    \n",
    "    def animate(frame_idx):\n",
    "        # Update game screen\n",
    "        img_game.set_array(frames[frame_idx])\n",
    "        \n",
    "        # Update AI vision\n",
    "        img_input.set_array(observations[frame_idx])\n",
    "        \n",
    "        # Update output bars\n",
    "        for bar, val in zip(bars, outputs[frame_idx]):\n",
    "            bar.set_width(val)\n",
    "            bar.set_color('green' if val > 0.5 else 'steelblue')\n",
    "        \n",
    "        # Update controller buttons\n",
    "        pressed = buttons[frame_idx]\n",
    "        for btn, patch in button_patches.items():\n",
    "            if btn in pressed:\n",
    "                patch.set_facecolor('yellow')\n",
    "            else:\n",
    "                patch.set_facecolor('lightgray')\n",
    "        \n",
    "        # Update info text\n",
    "        i = info[frame_idx]\n",
    "        info_text.set_text(f\"Step: {i['step']} | X: {i['x']} | Coins: {i['coins']}\")\n",
    "        \n",
    "        return [img_game, img_input, info_text] + list(bars) + list(button_patches.values())\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, animate, frames=len(frames),\n",
    "        interval=1000/fps, blit=False\n",
    "    )\n",
    "    \n",
    "    plt.close()\n",
    "    return anim\n",
    "\n",
    "# Create and display the MarI/O-style visualization\n",
    "print(\"üéÆ MarI/O-Style Visualization\")\n",
    "print(\"=\"*50)\n",
    "print(\"‚Ä¢ LEFT: Game screen\")\n",
    "print(\"‚Ä¢ MIDDLE-LEFT: What the AI 'sees' (13√ó13 downscaled grayscale)\")\n",
    "print(\"‚Ä¢ MIDDLE-RIGHT: Network output activations (green = pressed)\")\n",
    "print(\"‚Ä¢ RIGHT: Controller showing button presses\")\n",
    "print()\n",
    "\n",
    "anim = create_mario_style_visualization(data, fps=15)\n",
    "HTML(anim.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea7b4d2",
   "metadata": {},
   "source": [
    "## 10. Visualize the Evolved Network\n",
    "\n",
    "NEAT evolves both the weights AND the structure of the network. Let's see what it created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310db4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_network(genome, config, filename=None):\n",
    "    \"\"\"\n",
    "    Visualize the evolved neural network topology.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import networkx as nx\n",
    "    except ImportError:\n",
    "        print(\"NetworkX not installed. Run: pip install networkx\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Get node info\n",
    "    input_keys = config.genome_config.input_keys\n",
    "    output_keys = config.genome_config.output_keys\n",
    "    \n",
    "    # Add all nodes\n",
    "    for node_id in input_keys:\n",
    "        G.add_node(node_id, layer='input')\n",
    "    \n",
    "    for node_id in output_keys:\n",
    "        G.add_node(node_id, layer='output')\n",
    "    \n",
    "    hidden_nodes = [n for n in genome.nodes.keys() \n",
    "                    if n not in input_keys and n not in output_keys]\n",
    "    for node_id in hidden_nodes:\n",
    "        G.add_node(node_id, layer='hidden')\n",
    "    \n",
    "    # Add connections\n",
    "    for conn_key, conn in genome.connections.items():\n",
    "        if conn.enabled:\n",
    "            G.add_edge(conn_key[0], conn_key[1], weight=conn.weight)\n",
    "    \n",
    "    # Create positions\n",
    "    pos = {}\n",
    "    \n",
    "    # Input nodes (left side, arranged in grid)\n",
    "    n_inputs = len(input_keys)\n",
    "    grid_size = int(np.sqrt(n_inputs))\n",
    "    for i, node_id in enumerate(input_keys):\n",
    "        row = i // grid_size\n",
    "        col = i % grid_size\n",
    "        pos[node_id] = (col * 0.1, -row * 0.1)\n",
    "    \n",
    "    # Output nodes (right side)\n",
    "    output_labels = ['A', 'B', 'LEFT', 'RIGHT', 'UP', 'DOWN']\n",
    "    for i, node_id in enumerate(output_keys):\n",
    "        pos[node_id] = (grid_size * 0.1 + 2, -i * 0.3 - grid_size * 0.05 / 2 + 0.75)\n",
    "    \n",
    "    # Hidden nodes (middle)\n",
    "    for i, node_id in enumerate(hidden_nodes):\n",
    "        pos[node_id] = (grid_size * 0.1 + 1, -i * 0.3 - grid_size * 0.05 / 2 + 0.5)\n",
    "    \n",
    "    # Draw\n",
    "    # Input nodes (small, gray)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=list(input_keys),\n",
    "                          node_color='lightgray', node_size=30)\n",
    "    \n",
    "    # Hidden nodes (medium, blue)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=hidden_nodes,\n",
    "                          node_color='lightblue', node_size=300)\n",
    "    \n",
    "    # Output nodes (large, green)\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=list(output_keys),\n",
    "                          node_color='lightgreen', node_size=500)\n",
    "    \n",
    "    # Draw edges with color based on weight\n",
    "    edges = G.edges(data=True)\n",
    "    weights = [e[2].get('weight', 0) for e in edges]\n",
    "    \n",
    "    if weights:\n",
    "        edge_colors = ['red' if w < 0 else 'green' for w in weights]\n",
    "        edge_widths = [min(abs(w) * 0.5, 3) for w in weights]\n",
    "        \n",
    "        nx.draw_networkx_edges(G, pos, edge_color=edge_colors, \n",
    "                              width=edge_widths, alpha=0.6,\n",
    "                              arrows=True, arrowsize=10)\n",
    "    \n",
    "    # Labels for output nodes\n",
    "    output_labels_dict = {node_id: output_labels[i] \n",
    "                         for i, node_id in enumerate(output_keys)}\n",
    "    nx.draw_networkx_labels(G, pos, labels=output_labels_dict, font_size=10)\n",
    "    \n",
    "    # Hidden node labels\n",
    "    hidden_labels = {n: str(n) for n in hidden_nodes}\n",
    "    nx.draw_networkx_labels(G, pos, labels=hidden_labels, font_size=8)\n",
    "    \n",
    "    plt.title(f\"Evolved Network Topology\\n\"\n",
    "             f\"({len(input_keys)} inputs ‚Üí {len(hidden_nodes)} hidden ‚Üí {len(output_keys)} outputs)\\n\"\n",
    "             f\"{len(G.edges())} connections | Green=positive, Red=negative weights\",\n",
    "             fontsize=12)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if filename:\n",
    "        plt.savefig(filename, dpi=150, bbox_inches='tight')\n",
    "        print(f\"Saved to {filename}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualize the winner network\n",
    "print(\"üß† Evolved Network Topology:\")\n",
    "print(f\"  Hidden nodes: {len([n for n in winner.nodes if n not in config.genome_config.input_keys and n not in config.genome_config.output_keys])}\")\n",
    "print(f\"  Connections: {len([c for c in winner.connections.values() if c.enabled])}\")\n",
    "print()\n",
    "\n",
    "draw_network(winner, config, f'{CHECKPOINT_DIR}/winner_network.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08641baa",
   "metadata": {},
   "source": [
    "## 11. Load and Continue Training (Optional)\n",
    "\n",
    "Resume training from a checkpoint or the best genome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be0c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To resume from a checkpoint:\n",
    "# checkpoint_path = './models/neat-checkpoint-XX'  # Replace XX with checkpoint number\n",
    "# population = neat.Checkpointer.restore_checkpoint(checkpoint_path)\n",
    "# winner = population.run(eval_genomes, 50)  # Run 50 more generations\n",
    "\n",
    "# To load and test a saved winner:\n",
    "# with open('./models/winner_genome.pkl', 'rb') as f:\n",
    "#     loaded_winner = pickle.load(f)\n",
    "# fitness, frames = evaluate_genome(loaded_winner, config, render=True)\n",
    "\n",
    "print(\"üí° To continue training, uncomment the code above and modify as needed.\")\n",
    "print()\n",
    "print(\"Available checkpoints:\")\n",
    "import glob\n",
    "checkpoints = sorted(glob.glob(f'{CHECKPOINT_DIR}/neat-checkpoint-*'))\n",
    "for cp in checkpoints[-5:]:  # Show last 5\n",
    "    print(f\"  {cp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e655bfd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Notes & Tips\n",
    "\n",
    "### Why NEAT works well for Mario:\n",
    "- **Evolves topology**: Automatically discovers how complex the network needs to be\n",
    "- **No gradients needed**: Works with any fitness function (even sparse rewards)\n",
    "- **Speciation**: Protects new innovations from being immediately eliminated\n",
    "- **Minimal networks**: Tends to find simple, efficient solutions\n",
    "\n",
    "### Tuning Tips:\n",
    "- **Population size**: Larger (100+) = more diversity, but slower\n",
    "- **Generations**: More generations = better results, typically 100-500 for good play\n",
    "- **Fitness function**: Experiment with different reward structures\n",
    "- **Memory addresses**: May need adjustment for different ROM versions\n",
    "\n",
    "### Memory Address Discovery:\n",
    "If Mario's position isn't being read correctly, you can search for the right addresses:\n",
    "1. Play the game manually and note a specific value (coins, position, etc.)\n",
    "2. Use a memory scanner to find addresses containing that value\n",
    "3. Update the `MEMORY` dict in `GBAEmulator` class\n",
    "\n",
    "### Performance Tips:\n",
    "- Training runs headless (no GUI) for maximum speed\n",
    "- Each genome evaluation is independent - could be parallelized\n",
    "- Checkpoints save every 5 generations by default"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
